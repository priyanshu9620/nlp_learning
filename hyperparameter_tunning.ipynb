{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2nBp/96iMULkLdPO9f06f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshu9620/nlp_learning/blob/master/hyperparameter_tunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "zD4UCLRUDda9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('diabetes.csv')"
      ],
      "metadata": {
        "id": "Tn8t7V14D0f6"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tHkucZNjD4vT",
        "outputId": "377987c6-9c10-46c7-c548-1bac8addac1c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b71a64bc-cc86-489f-9dde-9caae8c527a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b71a64bc-cc86-489f-9dde-9caae8c527a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b71a64bc-cc86-489f-9dde-9caae8c527a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b71a64bc-cc86-489f-9dde-9caae8c527a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83f298a6-d00b-402c-bf0a-87e06628d158\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83f298a6-d00b-402c-bf0a-87e06628d158')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83f298a6-d00b-402c-bf0a-87e06628d158 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.iloc[:,:-1].values #except last row\n",
        "y=df.iloc[:,-1].values #last row"
      ],
      "metadata": {
        "id": "v9DEQm0AD597"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfhJcHMtExkN",
        "outputId": "01a21f95-cc75-4137-d1bf-af5d2559d9c5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CPQT400Eyrb",
        "outputId": "854a282b-9cc6-408b-87d9-0bbac5484291"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
            " 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0\n",
            " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
            " 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
            " 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0\n",
            " 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1\n",
            " 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1\n",
            " 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
            " 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
            " 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## used standardization to convert the data between -1 to 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()"
      ],
      "metadata": {
        "id": "NxfxyPQDEz97"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_new=scaler.fit_transform(x)\n",
        "print(x_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkZcGez0FD4-",
        "outputId": "d49138cd-3e05-4ea4-b110-9adb7bc4a25f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
            "   1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
            "  -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
            "  -0.10558415]\n",
            " ...\n",
            " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
            "  -0.27575966]\n",
            " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
            "   1.17073215]\n",
            " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
            "  -0.87137393]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=x_new\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BEdkI73FIgG",
        "outputId": "a48c92da-cb5e-4305-a566-ad612189fd61"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuJdHxUvFM2P",
        "outputId": "a833b915-7958-4c41-b560-0000a8fbefb1"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "xzr4m9lIFhhk"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "UfmOymh3FiaH"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see we have 8 features as x so roughly 32 neurons taken\n",
        "model=Sequential()\n",
        "#only input and output layer currently\n",
        "model.add(Dense(32,activation='relu',input_dim=8))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "#binary classification so\n",
        "\n",
        "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qpWG4b5pGF4w"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=32,epochs=100,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXbPwC_5G4YH",
        "outputId": "50f609de-9712-47f2-bdf8-a135c93f8b4c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 0.7230 - accuracy: 0.4837 - val_loss: 0.6843 - val_accuracy: 0.5455\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.6287 - val_loss: 0.6339 - val_accuracy: 0.6429\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.6987 - val_loss: 0.5927 - val_accuracy: 0.7013\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7329 - val_loss: 0.5574 - val_accuracy: 0.7532\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7427 - val_loss: 0.5317 - val_accuracy: 0.7792\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7524 - val_loss: 0.5140 - val_accuracy: 0.7857\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7622 - val_loss: 0.4988 - val_accuracy: 0.7727\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7590 - val_loss: 0.4874 - val_accuracy: 0.7792\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7557 - val_loss: 0.4797 - val_accuracy: 0.7857\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7622 - val_loss: 0.4730 - val_accuracy: 0.7922\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7638 - val_loss: 0.4695 - val_accuracy: 0.7987\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7687 - val_loss: 0.4661 - val_accuracy: 0.7857\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7671 - val_loss: 0.4650 - val_accuracy: 0.7792\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7720 - val_loss: 0.4630 - val_accuracy: 0.7857\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7704 - val_loss: 0.4611 - val_accuracy: 0.7857\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7720 - val_loss: 0.4608 - val_accuracy: 0.7857\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7736 - val_loss: 0.4603 - val_accuracy: 0.7857\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7720 - val_loss: 0.4601 - val_accuracy: 0.7857\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7720 - val_loss: 0.4606 - val_accuracy: 0.7922\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7752 - val_loss: 0.4609 - val_accuracy: 0.7922\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7752 - val_loss: 0.4618 - val_accuracy: 0.7922\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7769 - val_loss: 0.4609 - val_accuracy: 0.7922\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7769 - val_loss: 0.4628 - val_accuracy: 0.7857\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4537 - accuracy: 0.7801 - val_loss: 0.4643 - val_accuracy: 0.7857\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7736 - val_loss: 0.4626 - val_accuracy: 0.7792\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7720 - val_loss: 0.4603 - val_accuracy: 0.7857\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7736 - val_loss: 0.4599 - val_accuracy: 0.7857\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7720 - val_loss: 0.4593 - val_accuracy: 0.7857\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7720 - val_loss: 0.4602 - val_accuracy: 0.7857\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7752 - val_loss: 0.4602 - val_accuracy: 0.7857\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7769 - val_loss: 0.4610 - val_accuracy: 0.7857\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7769 - val_loss: 0.4600 - val_accuracy: 0.7857\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7769 - val_loss: 0.4612 - val_accuracy: 0.7922\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7752 - val_loss: 0.4603 - val_accuracy: 0.7857\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7720 - val_loss: 0.4600 - val_accuracy: 0.7922\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7736 - val_loss: 0.4616 - val_accuracy: 0.7922\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7769 - val_loss: 0.4621 - val_accuracy: 0.7922\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7785 - val_loss: 0.4625 - val_accuracy: 0.7922\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7785 - val_loss: 0.4623 - val_accuracy: 0.7922\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7704 - val_loss: 0.4623 - val_accuracy: 0.7922\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7736 - val_loss: 0.4626 - val_accuracy: 0.7922\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7785 - val_loss: 0.4629 - val_accuracy: 0.7857\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7736 - val_loss: 0.4639 - val_accuracy: 0.7857\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7736 - val_loss: 0.4642 - val_accuracy: 0.7792\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7769 - val_loss: 0.4649 - val_accuracy: 0.7792\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7769 - val_loss: 0.4650 - val_accuracy: 0.7857\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7785 - val_loss: 0.4644 - val_accuracy: 0.7857\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7769 - val_loss: 0.4629 - val_accuracy: 0.7987\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7801 - val_loss: 0.4637 - val_accuracy: 0.7987\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7785 - val_loss: 0.4643 - val_accuracy: 0.7987\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7785 - val_loss: 0.4639 - val_accuracy: 0.7987\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7834 - val_loss: 0.4635 - val_accuracy: 0.7987\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7785 - val_loss: 0.4638 - val_accuracy: 0.7987\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7785 - val_loss: 0.4653 - val_accuracy: 0.7922\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7769 - val_loss: 0.4657 - val_accuracy: 0.7987\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7769 - val_loss: 0.4660 - val_accuracy: 0.7922\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7818 - val_loss: 0.4655 - val_accuracy: 0.7987\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7769 - val_loss: 0.4651 - val_accuracy: 0.7987\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7752 - val_loss: 0.4657 - val_accuracy: 0.7922\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7785 - val_loss: 0.4664 - val_accuracy: 0.7922\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7801 - val_loss: 0.4646 - val_accuracy: 0.7987\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7801 - val_loss: 0.4655 - val_accuracy: 0.7987\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7834 - val_loss: 0.4645 - val_accuracy: 0.8052\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7818 - val_loss: 0.4652 - val_accuracy: 0.8052\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7866 - val_loss: 0.4666 - val_accuracy: 0.7987\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7818 - val_loss: 0.4691 - val_accuracy: 0.7987\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7834 - val_loss: 0.4683 - val_accuracy: 0.7987\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7818 - val_loss: 0.4685 - val_accuracy: 0.7987\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7801 - val_loss: 0.4674 - val_accuracy: 0.8052\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7866 - val_loss: 0.4671 - val_accuracy: 0.8052\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7866 - val_loss: 0.4663 - val_accuracy: 0.7987\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7866 - val_loss: 0.4666 - val_accuracy: 0.8052\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7883 - val_loss: 0.4652 - val_accuracy: 0.8052\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7948 - val_loss: 0.4653 - val_accuracy: 0.8117\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.4659 - val_accuracy: 0.7987\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7948 - val_loss: 0.4651 - val_accuracy: 0.8052\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7948 - val_loss: 0.4653 - val_accuracy: 0.8052\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.4650 - val_accuracy: 0.8052\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.4650 - val_accuracy: 0.8117\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7866 - val_loss: 0.4656 - val_accuracy: 0.8052\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7948 - val_loss: 0.4635 - val_accuracy: 0.8117\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7932 - val_loss: 0.4640 - val_accuracy: 0.8052\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7915 - val_loss: 0.4655 - val_accuracy: 0.8117\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7915 - val_loss: 0.4654 - val_accuracy: 0.8052\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7915 - val_loss: 0.4647 - val_accuracy: 0.8052\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7932 - val_loss: 0.4649 - val_accuracy: 0.8052\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.4653 - val_accuracy: 0.7987\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7883 - val_loss: 0.4637 - val_accuracy: 0.8117\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7948 - val_loss: 0.4636 - val_accuracy: 0.8117\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7932 - val_loss: 0.4634 - val_accuracy: 0.8117\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7964 - val_loss: 0.4638 - val_accuracy: 0.8117\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7932 - val_loss: 0.4633 - val_accuracy: 0.8117\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7948 - val_loss: 0.4655 - val_accuracy: 0.8052\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7980 - val_loss: 0.4663 - val_accuracy: 0.8052\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7964 - val_loss: 0.4663 - val_accuracy: 0.8052\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7932 - val_loss: 0.4673 - val_accuracy: 0.8052\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7883 - val_loss: 0.4637 - val_accuracy: 0.8117\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7932 - val_loss: 0.4633 - val_accuracy: 0.8052\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7980 - val_loss: 0.4637 - val_accuracy: 0.8117\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7932 - val_loss: 0.4638 - val_accuracy: 0.7987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788973f4fd90>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**so we have done model training and we got trainning acc as 81% and test acc as 78% so now we will see hyperparameter tunning\n",
        "see one thing is we try ourself go change optimizer or nodes or every thing by our own and another thing is we automate this process using keras tunner**"
      ],
      "metadata": {
        "id": "F0DdJzYvHlhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now whats next\n",
        "# 1. how to select appropriate optimizer\n",
        "# 2. no. of node in a layer\n",
        "# 3. how to select no. of hidden layer\n",
        "# 4. all in one model implementing all"
      ],
      "metadata": {
        "id": "aSoh31XzG_L0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaDjjmonIoLA",
        "outputId": "f75ed6eb-4c30-42f1-e31b-cc3582b413ec"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "zNfyPVmtIyBb"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in keras_tuner u build your model again inside a function which has hp as parameter and we pass all\n",
        "# new things as choice x to this hp and all those choices run one by one\n",
        "\n",
        "def build_model(hp):\n",
        "  model=Sequential()\n",
        "  model.add(Dense(32,activation='relu',input_dim=8))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  variable_name=hp.Choice('optimizer',values=['adam','rmsprop','adadelta'])\n",
        "  model.compile(optimizer=variable_name,loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# see simple pass this choice there and rest every thing same\n",
        "\n",
        "# inside choice u pass two things one is the name of that thing just anything u can give\n",
        "# second is the actual values to be used"
      ],
      "metadata": {
        "id": "Td_MrNyDI3fS"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now u create the tunner which is of randomsearch class and its a contructor which we used here\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtTO9JrbKb1G",
        "outputId": "ca609778-4d19-4a18-f076-d46d1cacc231"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from ./untitled_project/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train,y_train,epochs=5,validation_data=(x_test,y_test))\n",
        "\n",
        "# here just finding the best model so using 5 epochs"
      ],
      "metadata": {
        "id": "Bhen1_kqMJ0P"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values\n",
        "\n",
        "# so this is the best optimizer we got"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDs6K8WCN1cf",
        "outputId": "9cc2f6ac-1f9b-494b-c203-1dbb7d407239"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'sgd'}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now u should not retrain your model rather according to training of 5 epoch the best model came which we ar eusing and hte further we are training that\n",
        "model=tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "TXsEHit8N-h0"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVWKMHxxOEXl",
        "outputId": "e6acdf47-e6c8-4293-96df-9a6cfefa1f44"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32)                288       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321 (1.25 KB)\n",
            "Trainable params: 321 (1.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=32,epochs=100,initial_epoch=6,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1FqzVguOGeg",
        "outputId": "715a3791-bf2a-47e0-bcdc-7ad38dd8cb4d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 0.5920 - accuracy: 0.7182 - val_loss: 0.5497 - val_accuracy: 0.7987\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7248 - val_loss: 0.5395 - val_accuracy: 0.7987\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7296 - val_loss: 0.5307 - val_accuracy: 0.7987\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7394 - val_loss: 0.5238 - val_accuracy: 0.7987\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7394 - val_loss: 0.5175 - val_accuracy: 0.7987\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7410 - val_loss: 0.5112 - val_accuracy: 0.7987\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7476 - val_loss: 0.5061 - val_accuracy: 0.7987\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7476 - val_loss: 0.5017 - val_accuracy: 0.7987\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7492 - val_loss: 0.4972 - val_accuracy: 0.7922\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7541 - val_loss: 0.4934 - val_accuracy: 0.7922\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7573 - val_loss: 0.4900 - val_accuracy: 0.7922\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7606 - val_loss: 0.4869 - val_accuracy: 0.7922\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7622 - val_loss: 0.4844 - val_accuracy: 0.7987\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7622 - val_loss: 0.4826 - val_accuracy: 0.7987\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7622 - val_loss: 0.4814 - val_accuracy: 0.7987\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7655 - val_loss: 0.4795 - val_accuracy: 0.7922\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7687 - val_loss: 0.4774 - val_accuracy: 0.7922\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7687 - val_loss: 0.4754 - val_accuracy: 0.7987\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7752 - val_loss: 0.4739 - val_accuracy: 0.7987\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7752 - val_loss: 0.4721 - val_accuracy: 0.7987\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7752 - val_loss: 0.4708 - val_accuracy: 0.7987\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7801 - val_loss: 0.4697 - val_accuracy: 0.7987\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7801 - val_loss: 0.4689 - val_accuracy: 0.7987\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7834 - val_loss: 0.4680 - val_accuracy: 0.7987\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7834 - val_loss: 0.4668 - val_accuracy: 0.7987\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7785 - val_loss: 0.4660 - val_accuracy: 0.7987\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7818 - val_loss: 0.4652 - val_accuracy: 0.7987\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7801 - val_loss: 0.4649 - val_accuracy: 0.7987\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7850 - val_loss: 0.4642 - val_accuracy: 0.7987\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7834 - val_loss: 0.4638 - val_accuracy: 0.7987\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7801 - val_loss: 0.4636 - val_accuracy: 0.7987\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7818 - val_loss: 0.4627 - val_accuracy: 0.7987\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7850 - val_loss: 0.4625 - val_accuracy: 0.8052\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7818 - val_loss: 0.4622 - val_accuracy: 0.8052\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7801 - val_loss: 0.4618 - val_accuracy: 0.7987\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7818 - val_loss: 0.4618 - val_accuracy: 0.7922\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7834 - val_loss: 0.4616 - val_accuracy: 0.7987\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7834 - val_loss: 0.4616 - val_accuracy: 0.7987\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7834 - val_loss: 0.4617 - val_accuracy: 0.8052\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7818 - val_loss: 0.4616 - val_accuracy: 0.8052\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7818 - val_loss: 0.4613 - val_accuracy: 0.8052\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7834 - val_loss: 0.4613 - val_accuracy: 0.8052\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7801 - val_loss: 0.4613 - val_accuracy: 0.8052\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7818 - val_loss: 0.4612 - val_accuracy: 0.8052\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7801 - val_loss: 0.4612 - val_accuracy: 0.8052\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7818 - val_loss: 0.4613 - val_accuracy: 0.8052\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7801 - val_loss: 0.4615 - val_accuracy: 0.8052\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7834 - val_loss: 0.4619 - val_accuracy: 0.8052\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7834 - val_loss: 0.4620 - val_accuracy: 0.8052\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7818 - val_loss: 0.4619 - val_accuracy: 0.8052\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7834 - val_loss: 0.4628 - val_accuracy: 0.8052\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7818 - val_loss: 0.4629 - val_accuracy: 0.8052\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7834 - val_loss: 0.4629 - val_accuracy: 0.8052\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7801 - val_loss: 0.4632 - val_accuracy: 0.8052\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7801 - val_loss: 0.4633 - val_accuracy: 0.7987\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7769 - val_loss: 0.4641 - val_accuracy: 0.7987\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7769 - val_loss: 0.4658 - val_accuracy: 0.7922\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7785 - val_loss: 0.4647 - val_accuracy: 0.7987\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7785 - val_loss: 0.4646 - val_accuracy: 0.7987\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7736 - val_loss: 0.4641 - val_accuracy: 0.7987\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7720 - val_loss: 0.4639 - val_accuracy: 0.7987\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7720 - val_loss: 0.4637 - val_accuracy: 0.7987\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7720 - val_loss: 0.4633 - val_accuracy: 0.8052\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7704 - val_loss: 0.4635 - val_accuracy: 0.8052\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7752 - val_loss: 0.4636 - val_accuracy: 0.8052\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7752 - val_loss: 0.4644 - val_accuracy: 0.8052\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7769 - val_loss: 0.4640 - val_accuracy: 0.8052\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7752 - val_loss: 0.4640 - val_accuracy: 0.8052\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7736 - val_loss: 0.4642 - val_accuracy: 0.8052\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7769 - val_loss: 0.4647 - val_accuracy: 0.8052\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7769 - val_loss: 0.4650 - val_accuracy: 0.8052\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7769 - val_loss: 0.4649 - val_accuracy: 0.8052\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7769 - val_loss: 0.4650 - val_accuracy: 0.8052\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7769 - val_loss: 0.4650 - val_accuracy: 0.8052\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7769 - val_loss: 0.4650 - val_accuracy: 0.8052\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7769 - val_loss: 0.4651 - val_accuracy: 0.8052\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7785 - val_loss: 0.4652 - val_accuracy: 0.8052\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7769 - val_loss: 0.4652 - val_accuracy: 0.8052\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7752 - val_loss: 0.4654 - val_accuracy: 0.8052\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7736 - val_loss: 0.4658 - val_accuracy: 0.8052\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7769 - val_loss: 0.4655 - val_accuracy: 0.8052\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7736 - val_loss: 0.4652 - val_accuracy: 0.8052\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7736 - val_loss: 0.4652 - val_accuracy: 0.8052\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7752 - val_loss: 0.4650 - val_accuracy: 0.8052\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7769 - val_loss: 0.4651 - val_accuracy: 0.8052\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7769 - val_loss: 0.4653 - val_accuracy: 0.8052\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7785 - val_loss: 0.4653 - val_accuracy: 0.8052\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7769 - val_loss: 0.4654 - val_accuracy: 0.8052\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7769 - val_loss: 0.4655 - val_accuracy: 0.8052\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7785 - val_loss: 0.4659 - val_accuracy: 0.8052\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7769 - val_loss: 0.4655 - val_accuracy: 0.8052\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7769 - val_loss: 0.4653 - val_accuracy: 0.8052\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7769 - val_loss: 0.4653 - val_accuracy: 0.8052\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7785 - val_loss: 0.4651 - val_accuracy: 0.8052\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78897660f730>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now our validation acc is 82%"
      ],
      "metadata": {
        "id": "nTniraY2OZkt"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# similarly last time i took 32 as the no. of neurons and just 2 layers so that can also be find similarly"
      ],
      "metadata": {
        "id": "M-BnyreVPKOX"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. for no. of neurons"
      ],
      "metadata": {
        "id": "_5fwVrj_Pkm9"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ejuFz4SMRCuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Dense(\n",
        "      hp.Choice('units', [8, 16, 32]),\n",
        "      activation='relu'))\n",
        "  model.add(keras.layers.Dense(1, activation='relu'))\n",
        "  model.compile(loss='mse')\n",
        "  return model"
      ],
      "metadata": {
        "id": "gbLGxNB9PndM"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pW22YgNlPpgA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}